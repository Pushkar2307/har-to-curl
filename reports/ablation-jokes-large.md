# Ablation Study: Token Efficiency vs Explainability

**Date:** 2026-02-13
**HAR file:** `examples/jokes/jokes.large.har` (1727 total entries, 254 after filtering)
**Query:** "Can you give me a curl command to get 5 jokes via API?"

## Results

*Latency = LLM API call time only (excludes parsing, filtering, dedup)*

| Configuration | Dedup | Candidates | Reasoning | Entries | Prompt Tok | Compl Tok | Total Tok | % vs Baseline | Latency | Match |
|---|---|---|---|---|---|---|---|---|---|---|
| Baseline (minimal) | ✗ | ✗ | ✗ | 254 | 42,055 | 61 | 42,116 | — | 1977ms | [253] |
| + Deduplication only | ✓ | ✗ | ✗ | 127 | 6,819 | 69 | 6,888 | -83.6% | 1880ms | [253] |
| + Candidates only | ✗ | ✓ | ✗ | 254 | 42,155 | 226 | 42,381 | +0.6% | 4605ms | [253] |
| + Reasoning only | ✗ | ✗ | ✓ | 254 | 42,082 | 129 | 42,211 | +0.2% | 2765ms | [253] |
| + Candidates + Reasoning | ✗ | ✓ | ✓ | 254 | 42,182 | 315 | 42,497 | +0.9% | 5828ms | [253] |
| Dedup + Candidates (default) | ✓ | ✓ | ✗ | 127 | 6,919 | 240 | 7,159 | -83.0% | 4499ms | [253] |
| All features (with reasoning) | ✓ | ✓ | ✓ | 127 | 6,946 | 267 | 7,213 | -82.9% | 6025ms | [253] |

## Isolated Feature Costs

| Feature | Prompt Δ | Completion Δ | Total Δ | What you get |
|---|---|---|---|---|
| Deduplication | -35,236 | +8 | -35,228 | URL compaction, fewer entries sent |
| Candidates + Confidence | +100 | +165 | +265 | Ranked alternatives with confidence bars |
| Reasoning text | +27 | +68 | +95 | Verbose thought process explanation |

## Shipping Default vs All Features

**Dedup + Candidates (shipping default):** 7,159 tokens (83.0% vs baseline)
- Confidence bars + candidate list provide the high-value UX
- Reasoning text omitted — adds ~68 completion tokens for limited end-user value

**All features (with reasoning):** 7,213 tokens
- Full transparency including verbose reasoning text (82.9% vs baseline)
- Available via `reasoning: true` flag for debugging or detailed analysis

## Correctness

**All configurations returned the same match** ✓ — feature flags do not affect accuracy.

## Matched Entry Details

**Baseline (minimal):** [253] https://v2.jokeapi.dev/joke/Any?amount=5
> The endpoint 'GET https://v2.jokeapi.dev/joke/Any?amount=5' directly matches the user's request for an API to get 5 jokes, as it specifies the amount parameter in the query string.

**+ Deduplication only:** [253] https://v2.jokeapi.dev/joke/Any?amount=5
> The endpoint 'https://v2.jokeapi.dev/joke/Any?amount=...' is specifically designed to retrieve jokes, and the query parameter 'amount' suggests that it can return a specified number of jokes, making it the best match for the user's request.

**+ Candidates only:** [253] https://v2.jokeapi.dev/joke/Any?amount=5
> The best match is the endpoint that retrieves 5 jokes, which directly aligns with the user's request for a curl command to get jokes via an API.

**+ Reasoning only:** [253] https://v2.jokeapi.dev/joke/Any?amount=5
> This endpoint specifically requests 5 jokes, which aligns perfectly with the user's request for a curl command to get jokes.

**+ Candidates + Reasoning:** [253] https://v2.jokeapi.dev/joke/Any?amount=5
> The endpoint `GET https://v2.jokeapi.dev/joke/Any?amount=5` is the best match as it directly corresponds to the user's request for an API to retrieve 5 jokes.

**Dedup + Candidates (default):** [253] https://v2.jokeapi.dev/joke/Any?amount=5
> The endpoint at index 253 is the best match as it directly requests jokes with a specified amount, aligning perfectly with the user's request for a curl command to get jokes via API.

**All features (with reasoning):** [253] https://v2.jokeapi.dev/joke/Any?amount=5
> The endpoint `https://v2.jokeapi.dev/joke/Any?amount=...` is the best match because it directly supports retrieving a specified number of jokes, which is exactly what the user is looking for.

---
*Generated by ablation.ts*
